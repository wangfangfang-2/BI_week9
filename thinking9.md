Thinking1：常用的文本分类方法都有哪些
传统文本分类方法：相关研究最早可以追溯到上世纪50年代，通过专家规则（Pattern）进行分类，在80年代初一度发展到利用知识工程建立专家系统，好处是短平快的解决top问题，但显然天花板非常低，不仅费时费力，覆盖的范围和准确率都非常有限。后来伴随着统计学习方法的发展，特别是90年代后互联网在线文本数量增长和机器学习学科的兴起，逐渐形成了一套解决大规模文本分类问题的经典玩法，这个阶段是人工特征工程+浅层分类模型。整个文本分类问题就拆分成了特征工程和分类器两部分。传统算法主要有基于字符串匹配的正向/逆向/双向最大匹配；基于理解的句法和语义分析消歧；基于统计的互信息/CRF方法。近年来随着深度学习的应用，WordEmbedding + Bi-LSTM+CRF方法逐渐成为主流。特征权重主要是经典的TF-IDF方法及其扩展方法，主要思路是一个词的重要度与在类别内的词频成正比，与所有类别出现的次数成反比。传统做法在文本表示方面除了向量空间模型，还有基于语义的文本表示方法，比如LDA主题模型、LSI/PLSI概率潜在语义索引等方法，一般认为这些方法得到的文本表示可以认为文档的深层表示，而word embedding文本分布式表示方法则是深度学习方法的重要基础。
深度学习文本分类模型：TextCNN，fastText，TextRNN，TextRNN + AttentionThinking2：RNN为什么会出现梯度消失
由w的梯度（T时刻）公式可得，由于tanh’ <= 1，训练过程大部分情况下tanh的导数是小于1的，如果Ws也在[0,1]之间，当T很大的时候，t+1到T时刻，累加连乘，最后连乘后的π值几乎为0。所以激活函数的导数和W连乘可以造成梯度消失；